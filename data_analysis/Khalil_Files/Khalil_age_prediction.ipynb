{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda14bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1993668/1855765672.py:2: DtypeWarning: Columns (7600,7601,7602,7603,7604,7605,7606,7607,7608,7609,7610,7611,7612,7613,7614,7615,7616,7617,7618,7619,7620,7621,7622,7623,7624,7625,7626,7627,7628,7629,7630,7631,7632,7633,7634,7635,7636,7637,7638,7639,7640,7641,7642,7643,7644,7645,7646,7647,7648,7649,7650,7651,7652,7653,7654,7655,7656,7657,7658,7659,7660,7661,7662,7663,7664,7665,7666,7667,7668,7669) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before cleaning: (13230, 8697)\n",
      "Final dataset shape: (13159, 8695)\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/vol/miltank/projects/practical_sose25/in_context_learning/data/other/radiomics_embeddings_fat.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Shape before cleaning: {df.shape}\")\n",
    "\n",
    "# Drop non-feature columns\n",
    "df = df.drop(columns=['eid'], errors='ignore')\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=['age'])\n",
    "\n",
    "X = df.drop(columns=['age'])\n",
    "y = df['age'].values.astype(np.float32)\n",
    "\n",
    "# Handle missing feature values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Final dataset shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b6476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/meta/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/meta/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/meta/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/meta/opt/anaconda3/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: [2033 2141 7599 7600 7601 7602 7603 7604 7605 7606 7607 7608 7609 7610\n",
      " 7611 7612 7613 7614 7615 7616 7617 7618 7619 7620 7621 7622 7623 7624\n",
      " 7625 7626 7627 7628 7629 7630 7631 7632 7633 7634 7635 7636 7637 7638\n",
      " 7639 7640 7641 7642 7643 7644 7645 7646 7647 7648 7649 7650 7651 7652\n",
      " 7653 7654 7655 7656 7657 7658 7659 7660 7661 7662 7663 7664 7665 7666\n",
      " 7667 7668]. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduced shape: (13159, 500)\n",
      "Explained variance ratio: 0.92\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=500)\n",
    "X_pca = pca.fit_transform(X_imputed)\n",
    "\n",
    "print(f\"PCA reduced shape: {X_pca.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_.sum():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4c2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_pca, y, train_size=0.7, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d063c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "model = TabPFNRegressor(device=device)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Test MAE: {mae:.3f}\")\n",
    "print(f\"Test MSE: {mse:.3f}\")\n",
    "print(f\"Test R2: {r2:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
